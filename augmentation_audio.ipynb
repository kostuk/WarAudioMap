{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: audiomentations in e:\\work\\soundmap\\.vevn\\lib\\site-packages (0.34.1)\n",
      "Requirement already satisfied: soxr<1.0.0,>=0.3.2 in e:\\work\\soundmap\\.vevn\\lib\\site-packages (from audiomentations) (0.3.7)\n",
      "Requirement already satisfied: librosa!=0.10.0,<0.11.0,>=0.8.0 in e:\\work\\soundmap\\.vevn\\lib\\site-packages (from audiomentations) (0.10.1)\n",
      "Requirement already satisfied: scipy<2,>=1.4.0 in e:\\work\\soundmap\\.vevn\\lib\\site-packages (from audiomentations) (1.12.0)\n",
      "Requirement already satisfied: numpy>=1.21.0 in e:\\work\\soundmap\\.vevn\\lib\\site-packages (from audiomentations) (1.26.3)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in e:\\work\\soundmap\\.vevn\\lib\\site-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (0.12.1)\n",
      "Requirement already satisfied: joblib>=0.14 in e:\\work\\soundmap\\.vevn\\lib\\site-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (1.3.2)\n",
      "Requirement already satisfied: msgpack>=1.0 in e:\\work\\soundmap\\.vevn\\lib\\site-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (1.0.7)\n",
      "Requirement already satisfied: audioread>=2.1.9 in e:\\work\\soundmap\\.vevn\\lib\\site-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (3.0.1)\n",
      "Requirement already satisfied: pooch>=1.0 in e:\\work\\soundmap\\.vevn\\lib\\site-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (1.8.0)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in e:\\work\\soundmap\\.vevn\\lib\\site-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (4.9.0)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in e:\\work\\soundmap\\.vevn\\lib\\site-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (1.4.0)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in e:\\work\\soundmap\\.vevn\\lib\\site-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (0.3)\n",
      "Requirement already satisfied: numba>=0.51.0 in e:\\work\\soundmap\\.vevn\\lib\\site-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (0.58.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in e:\\work\\soundmap\\.vevn\\lib\\site-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (5.1.1)\n",
      "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in e:\\work\\soundmap\\.vevn\\lib\\site-packages (from numba>=0.51.0->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (0.41.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in e:\\work\\soundmap\\.vevn\\lib\\site-packages (from pooch>=1.0->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (2.31.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in e:\\work\\soundmap\\.vevn\\lib\\site-packages (from pooch>=1.0->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (4.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in e:\\work\\soundmap\\.vevn\\lib\\site-packages (from pooch>=1.0->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (23.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in e:\\work\\soundmap\\.vevn\\lib\\site-packages (from scikit-learn>=0.20.0->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (3.2.0)\n",
      "Requirement already satisfied: cffi>=1.0 in e:\\work\\soundmap\\.vevn\\lib\\site-packages (from soundfile>=0.12.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (1.16.0)\n",
      "Requirement already satisfied: pycparser in e:\\work\\soundmap\\.vevn\\lib\\site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (2.21)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\work\\soundmap\\.vevn\\lib\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (2023.11.17)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\work\\soundmap\\.vevn\\lib\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\work\\soundmap\\.vevn\\lib\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\work\\soundmap\\.vevn\\lib\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (2.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -atplotlib (e:\\work\\soundmap\\.vevn\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (e:\\work\\soundmap\\.vevn\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (e:\\work\\soundmap\\.vevn\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (e:\\work\\soundmap\\.vevn\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (e:\\work\\soundmap\\.vevn\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (e:\\work\\soundmap\\.vevn\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install audiomentations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from audiomentations import Compose, Gain, GainTransition, AddGaussianNoise,AddBackgroundNoise, TimeStretch, PitchShift, Shift\n",
    "import numpy as np\n",
    "import os \n",
    "import keras.layers as layers\n",
    "import tensorflow as tf\n",
    "import tensorflow_io as tfio\n",
    "import librosa\n",
    "import librosa.display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "augment = Compose([\n",
    "    AddBackgroundNoise(sounds_path=\"./background_noises\"), \n",
    "    AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.015, p=0.5),\n",
    "    Gain(),\n",
    "    Shift(min_shift=-0.05, max_shift=0.05, p=0.5),\n",
    "])\n",
    "\n",
    "\n",
    "class Augmentation(layers.Layer):\n",
    "  def __init__(self, augmentation, sample_rate=32000):\n",
    "    super(Augmentation, self).__init__()\n",
    "    self.augmentation = augmentation\n",
    "    self.sample_rate = sample_rate\n",
    "        \n",
    "  def call(self, waves):\n",
    "    waves = self.augmentation(samples=waves, sample_rate=self.sample_rate)\n",
    "    return waves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentLayer = Augmentation(augment, 16000)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename file in folder to format like 00011.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_lim_path = 'raw_data_1s'\n",
    "batch_size = 32\n",
    "seed = 42\n",
    "desired_sr=44100\n",
    "\n",
    "# Get list of file paths and corresponding labels\n",
    "file_paths = []\n",
    "labels = []\n",
    "def load_data( folder_lim_path, folder_name):\n",
    "# Rename file\n",
    "    files = []\n",
    "    labels = []\n",
    "    path = os.path.join( folder_lim_path, folder_name)\n",
    "    for f in os.listdir(path):\n",
    "        full_name = os.path.join(path, f)\n",
    "        files.append(full_name)\n",
    "        labels.append(folder_name)\n",
    "\n",
    "    \n",
    "    return files, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths =[]\n",
    "labels=[]\n",
    "f,l = load_data( folder_lim_path, 'pushka')\n",
    "file_paths+=f\n",
    "labels+=l\n",
    "f,l = load_data( folder_lim_path, 'none')\n",
    "file_paths+=f\n",
    "labels+=l\n",
    "f,l = load_data( folder_lim_path, 'geran')\n",
    "file_paths+=f\n",
    "labels+=l\n",
    "\n",
    "# Shuffle data and split into training and validation sets\n",
    "num_samples = len(file_paths)\n",
    "indices = np.random.permutation(num_samples)\n",
    "split = int(0.8 * num_samples)  # 80-20 split\n",
    "\n",
    "train_paths = [file_paths[i] for i in indices[:split]]\n",
    "train_labels = [labels[i] for i in indices[:split]]\n",
    "\n",
    "val_paths = [file_paths[i] for i in indices[split:]]\n",
    "val_labels = [labels[i] for i in indices[split:]]\n",
    "\n",
    "# Create datasets for training and validation\n",
    "print(train_paths)\n",
    "print(train_labels)\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_paths, train_labels))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_paths, val_labels))\n",
    "\n",
    "# Function to load and process audio files\n",
    "\n",
    "\n",
    "# Shuffle data and split into training and validation sets\n",
    "num_samples = len(file_paths)\n",
    "indices = np.random.permutation(num_samples)\n",
    "split = int(0.8 * num_samples)  # 80-20 split\n",
    "\n",
    "train_paths = [file_paths[i] for i in indices[:split]]\n",
    "train_labels = [labels[i] for i in indices[:split]]\n",
    "\n",
    "val_paths = [file_paths[i] for i in indices[split:]]\n",
    "val_labels = [labels[i] for i in indices[split:]]\n",
    "\n",
    "\n",
    "# Create datasets for training and validation\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_paths, train_labels))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_paths, val_labels))\n",
    "\n",
    "# Utility functions for loading audio files and making sure the sample rate is correct.\n",
    "\n",
    "@tf.function\n",
    "def load_wav_mono(filename, sr=32000):\n",
    "    \"\"\" Load a WAV file, convert it to a float tensor, resample to 16 kHz single-channel audio. \"\"\"\n",
    "    file_contents = tf.io.read_file(filename)\n",
    "    wav, sample_rate = tf.audio.decode_wav(\n",
    "          file_contents,\n",
    "          desired_channels=1)\n",
    "    wav = tf.squeeze(wav, axis=-1)\n",
    "    sample_rate = tf.cast(sample_rate, dtype=tf.int64)\n",
    "    wav = tfio.audio.resample(wav, rate_in=sample_rate, rate_out=sr)\n",
    "    return wav\n",
    "\n",
    "def load_wav_for_map(filename, label):\n",
    "  return load_wav_mono(filename, desired_sr), label\n",
    "\n",
    "def load_and_augment_audio(file_path, label):\n",
    "    audio = load_wav_mono(file_path, desired_sr)\n",
    "    # audio = augment(samples=audio, sample_rate=desired_sr)\n",
    "    return audio, label\n",
    "\n",
    "train_dataset =     train_dataset.map(load_and_augment_audio, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "val_dataset = val_dataset.map(load_wav_for_map)\n",
    "# Shuffle and batch the datasets\n",
    "train_dataset = train_dataset.shuffle(buffer_size=len(train_paths), seed=seed)\n",
    "train_dataset = train_dataset.batch(batch_size)\n",
    "val_dataset = val_dataset.batch(batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augmetion_audio_file_split(file_path, folder_lim_path, folder_name ,folder_lim_time, offset=1,  desired_sr=44100):\n",
    "    # Создайте пустой DataFrame для хранения результатов\n",
    "\n",
    "    folder  = os.path.join(folder_lim_path, folder_name)\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "    for filename in os.listdir(folder):\n",
    "        file_path = os.path.join(folder, filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)\n",
    "        except Exception as e:\n",
    "            print('Failed to delete %s. Reason: %s' % (file_path, e))\n",
    "\n",
    "    folder  = os.path.join(folder_path, folder_name)\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.endswith('.wav'): \n",
    "            file_path = os.path.join(folder_path, folder_name, filename)\n",
    "            audio, sample_rate = librosa.load(file_path, sr=desired_sr)\n",
    "            # Получение длины в секундах  \n",
    "            audio_length = len(audio) / sample_rate\n",
    "            folder_lim_time_sample = int(folder_lim_time*sample_rate)\n",
    "            offset_sample = int(offset*folder_lim_time_sample)\n",
    "            start_sample=0\n",
    "            end_sample=folder_lim_time_sample\n",
    "            sub_number =0\n",
    "            while end_sample <= len(audio):\n",
    "                sub_number = sub_number+1\n",
    "                audio_split = audio[start_sample:end_sample]\n",
    "                filename_new = filename[:-4] + f\"_{sub_number:03}.wav\"\n",
    "                file_path_lim = os.path.join(folder_lim_path,folder_name, filename_new)\n",
    "                sf.write(file_path_lim, audio_split, sample_rate, subtype='PCM_24')\n",
    "\n",
    "                start_sample=start_sample+offset_sample\n",
    "                end_sample=end_sample+offset_sample\n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "def augmetion_audio_file_select(file_path, folder_lim_path, folder_name ,folder_lim_time, event_start=0.3, desired_sr=44100):\n",
    "    \n",
    "    # Specify the desired sampling rate (e.g., 44100 Hz)\n",
    "    # desired_sr \n",
    "\n",
    "    # Создайте пустой DataFrame для хранения результатов\n",
    "    file = []\n",
    "    pick = []\n",
    "    power = []\n",
    "\n",
    "    # Путь к папке, содержащей ваши WAV-файлы\n",
    "    data_csv = {'File':[], 'Pick':[], 'Power':[]}\n",
    "    ##\n",
    "    folder  = os.path.join(folder_lim_path, folder_name)\n",
    "    for filename in os.listdir(folder):\n",
    "        file_path = os.path.join(folder, filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)\n",
    "        except Exception as e:\n",
    "            print('Failed to delete %s. Reason: %s' % (file_path, e))\n",
    "\n",
    "    folder  = os.path.join(folder_path, folder_name)\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.endswith('.wav'): \n",
    "            file_path = os.path.join(folder_path, folder_name, filename)\n",
    "            audio, sample_rate = librosa.load(file_path, sr=desired_sr)\n",
    "            # Получение длины в секундах  \n",
    "            audio_length = len(audio) / sample_rate\n",
    "            ( jump_x, jump_y  ) = get_auduo_jump_power(audio, sample_rate)\n",
    "            if(len(jump_x)==0):\n",
    "                print(filename, jump_x)\n",
    "            else:\n",
    "                data_csv['File'].append(filename)\n",
    "                data_csv['Pick'].append(jump_x[0])\n",
    "                data_csv ['Power'].append(jump_y[0])\n",
    "                folder_lim_time_sample = int(folder_lim_time*sample_rate)\n",
    "                if audio_length < 1:\n",
    "                    padding = np.zeros(int(folder_lim_time_sample - len(audio)))\n",
    "                    audio = np.concatenate(( padding, audio))\n",
    "                else:\n",
    "                    pik_time = jump_x[0]\n",
    "                    pik_time_sample = int(pik_time*sample_rate)\n",
    "                    start_time = pik_time_sample-int(folder_lim_time_sample*event_start)\n",
    "                    pik_times=[start_time, start_time+folder_lim_time_sample]\n",
    "                    if pik_times[0] < 0:\n",
    "                        pik_times=[0, folder_lim_time_sample]\n",
    "                    if pik_times[1] > len(audio):\n",
    "                        pik_times=[len(audio-folder_lim_time_sample), len(audio)]\n",
    "\n",
    "                    audio = audio[pik_times[0]:pik_times[1]]\n",
    "                file_path_lim = os.path.join(folder_lim_path,folder_name, filename)\n",
    "                sf.write(file_path_lim, audio, sample_rate, subtype='PCM_24')\n",
    "\n",
    "    df = pd.DataFrame(data_csv) \n",
    "\n",
    "    # сохранение в Csv\n",
    "    df.to_csv(os.path.join(folder_path, f'{folder_name}.xlsx'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = 'raw_data'\n",
    "folder_lim_path = 'raw_data_1s'\n",
    "folder_name = 'pushka'\n",
    "folder_lim_time = 1\n",
    "augmetion_audio_file_select(folder_path, folder_lim_path, folder_name, folder_lim_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = 'raw_data'\n",
    "folder_lim_path = 'raw_data_1s'\n",
    "folder_lim_time = 1\n",
    "augmetion_audio_file_split(folder_path, folder_lim_path, 'geran', folder_lim_time)\n",
    "augmetion_audio_file_split(folder_path, folder_lim_path, 'none', folder_lim_time)\n",
    "augmetion_audio_file_split(folder_path, folder_lim_path, 'roked', folder_lim_time)\n",
    "augmetion_audio_file_split(folder_path, folder_lim_path, 'shots', folder_lim_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_name = \"00316.wav\"\n",
    "file_path = os.path.join(folder_path,folder_name, file_name)\n",
    "ipd.Audio(file_path)\n",
    "file_path = os.path.join(folder_lim_path,folder_name, file_name)\n",
    "ipd.Audio(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio, sample_rate = librosa.load(file_path, sr=desired_sr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Need show wave from audio array       \n",
    "\n",
    "plt.subplots()\n",
    "librosa.display.waveshow(audio, sr=sample_rate)\n",
    "plt.title(file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frameSize = 2048\n",
    "hopSize = 512\n",
    "stft_audio = librosa.stft(audio, n_fft = frameSize, hop_length = hopSize)\n",
    "D_harmonic, D_percussive = librosa.decompose.hpss(stft_audio)\n",
    "\n",
    "stft_audio_db = librosa.amplitude_to_db(np.abs(stft_audio), ref=np.max)\n",
    "print(stft_audio.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "get_auduo_jump_power(audio, sample_rate, show_chart=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stft_audio = librosa.stft(audio)#, n_fft = frameSize, hop_length = hopSize)\n",
    "D_harmonic, D_percussive = librosa.decompose.hpss(stft_audio)\n",
    "\n",
    "#rp = np.max(np.abs(stft_audio))\n",
    "rp = np.max(stft_audio )\n",
    "print(rp)\n",
    "rp = np.max\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.subplot(3, 1, 1)\n",
    "librosa.display.specshow(librosa.power_to_db(stft_audio, ref=rp),sr=sample_rate, y_axis='log')\n",
    "plt.colorbar()\n",
    "plt.title('Full spectrogram')\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "librosa.display.specshow(librosa.power_to_db(D_harmonic, ref=rp), sr=sample_rate,y_axis='log')\n",
    "plt.colorbar()\n",
    "plt.title('Harmonic spectrogram')\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "librosa.display.specshow(librosa.power_to_db(D_percussive, ref=rp),sr=sample_rate, y_axis='log', x_axis='time')\n",
    "plt.colorbar()\n",
    "plt.title('Percussive spectrogram')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "img = librosa.display.specshow(stft_audio_db,sr=sample_rate, x_axis='time', y_axis='log', ax=ax)\n",
    "ax.set(title='Now with labeled axes!')\n",
    "fig.colorbar(img, ax=ax, format=\"%+2.f dB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "M = librosa.feature.melspectrogram(y=audio, sr=sample_rate)\n",
    "M_db = librosa.power_to_db(M, ref=np.max)\n",
    "M_db = librosa.amplitude_to_db(M, ref=np.max)\n",
    "img = librosa.display.specshow(M_db, y_axis='mel',sr=sample_rate, x_axis='time', ax=ax)\n",
    "ax.set(title='Mel spectrogram display')\n",
    "fig.colorbar(img, ax=ax, format=\"%+2.f dB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".vevn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
